# ✅ YunMin-EfficientData Granular Task 목록

이 문서는 `YunMin-EfficientData` 프로젝트의 각 phase별로 **간결하며 검증 가능한 세부 작업(Task)** 을 정의합니다. 각 task는 **명확한 입력/출력 조건**, **구현 기준**, **테스트 방식**을 포함해야 합니다.

---

## 🧹 Phase 1: 중복 제거 (SlimPajama 기반)

### 📁 1-1. 데이터 준비

* [ ] 로컬 저장 공간 부족으로 인해 데이터는 클라우드 스토리지(S3, GCS 등)에 업로드
* [ ] 클라우드 스토리지에서 데이터를 직접 로딩하는 코드 작성 (예: boto3, gcloud)
* [ ] 클라우드 스토리지의 데이터를 JSONL 형식인지 검증 (`file.endswith('.jsonl')`)
* [ ] JSONL 파일 내 각 줄이 유효한 JSON 객체인지 검사 (`json.loads(line)` 테스트 수행)
* [ ] 문서 단위로 데이터를 정리 (공백 제거 및 특수문자 정규화)
* [ ] 정리된 데이터는 클라우드 스토리지 내 별도 폴더(`dedup_ready/`)에 저장
* [ ] 처리 전후 데이터 샘플(각 5개씩)을 비교하여 사람이 직접 검수

### 🧠 1-2. MinHash 중복 탐지 구현

* [ ] 띄어쓰기 기반 문장 분리 및 5-gram 토큰 리스트 생성 (`token_ngrams` 함수 작성)
* [ ] MinHash 서명 생성 코드 구현 (`datasketch` 라이브러리 활용)
* [ ] 서명을 기반으로 LSH 테이블 구축
* [ ] 유사도 ≥ 0.8 이상인 문서쌍 쿼리 기능 검증 (임의 샘플 10쌍 검사)
* [ ] LSH 테이블 구축 및 쿼리 속도 기록

### 🧹 1-3. 중복 제거 수행

* [ ] 클러스터링된 유사 문서에서 대표 문서만 선택 (토큰 수 또는 최신 날짜 기준)
* [ ] 중복 제거 결과를 클라우드의 `deduped/` 디렉토리에 저장
* [ ] 중복 제거 전후 문서 개수 및 중복률을 기록 (`dedup_log.csv`)
* [ ] 중복 제거 처리 시간 기록

---

## 📦 Phase 2: 포맷 변환 (Youmu 기반)

### 🔄 2-1. JSONL → Parquet 변환

* [ ] 클라우드 스토리지에서 JSONL 파일 로딩 (`deduped/`)
* [ ] Parquet 형식으로 변환 코드 작성 (pyarrow 사용)
* [ ] 필요한 컬럼만 선택하여 저장 (`text`, `source`, `tokens`, `lang`, `domain`)
* [ ] null 필드 제거 및 schema 강제 지정
* [ ] 변환된 파일은 클라우드의 `parquet_ready/` 디렉토리에 저장
* [ ] 변환된 Parquet 파일의 유효성 및 행 개수 검증

### 🧪 2-2. 로딩 속도 및 메모리 검증

* [ ] PyTorch DataLoader로 Parquet 파일을 클라우드 스토리지에서 직접 로딩
* [ ] 배치 크기 16 기준으로 로딩 속도 및 메모리 사용량 기록 (`tracemalloc`, `time`)
* [ ] JSONL 대비 로딩 성능 비교 분석 및 결과 기록

---

## 🧠 Phase 3: DEM 학습 및 병합

### 🧩 3-1. 개별 LoRA 모델 학습

* [ ] 각 도메인별 데이터셋으로 LoRA 모델을 개별적으로 학습
* [ ] 학습 과정에서 loss 및 evaluation loss 기록
* [ ] 학습 로그는 클라우드의 `logs/train_<domain>.log`에 저장
* [ ] 최종 모델 파라미터를 클라우드에 저장

### 🧮 3-2. 모델 차이 벡터 생성

* [ ] Base 모델과 개별 학습된 모델 간의 파라미터 차이 계산
* [ ] 계산된 차이 벡터를 numpy 형식으로 클라우드에 저장 (`diff_<domain>.npy`)
* [ ] 차이 벡터의 norm 값 sanity check

### ➕ 3-3. 병합 및 검증

* [ ] 설정된 가중치 기준으로 차이 벡터를 Base 모델에 병합
* [ ] 병합된 모델의 유효성 검사 (임의 문장 10개 추론)
* [ ] Base 모델과 병합 모델 간의 성능 비교 분석
* [ ] 성능 향상이 명확한 문장 사례를 최소 3개 포함하여 결과 보고

---

## 🔬 Phase 4: 통합 테스트 및 리포트

### ⚙️ 4-1. E2E 파이프라인 테스트

* [ ] 전체 파이프라인 자동화 스크립트 (`scripts/run_pipeline.sh`) 작성
* [ ] 파이프라인 실행 및 단계별 성공 여부 확인 ("✅ success" 출력)
* [ ] 각 단계별 실행 시간과 오류 로그를 클라우드에 기록 (`pipeline_run.log`, `pipeline_errors.log`)

### 📈 4-2. 성능 평가 및 비교

* [ ] 중복 제거 전후 데이터 크기 및 용량 비교
* [ ] JSONL과 Parquet 간의 로딩 성능 벤치마크 및 기록 (`benchmark/io_speed_comparison.csv`)
* [ ] 모델 병합 전후 perplexity와 BLEU score 측정 및 성능 요약 (`results/perf_summary.md`)

### 📝 4-3. 최종 보고서 작성

* [ ] 전체 파이프라인 수행 결과를 요약한 문서 작성 (`docs/report.md`)
* [ ] 개선 사항 3가지, 한계점 2가지, 후속 제안 2가지 포함
* [ ] 정성 및 정량 지표 모두 포함한 평가 작성

---

각 작업은 Git 커밋 기준으로 로그가 남아야 하며, 테스트 코드(`tests/`) 내 최소 1개 이상의 자동 검증 스크립트를 포함해야 합니다.
